从第二周开始记录。研究方向：从outlier切入，高效微调。

###   
A Refined Analysis of Massive Activations in LLMs  

[arXiv:2503.22329](https://arxiv.org/abs/2503.22329)

---

- 新知
    - 前人
        - 大部分模型的异常激活值满足特征：在很早的层剧烈增大，中间层基本恒定，最后几层迅速消失。gemma等小部分模型异常激活值逐渐持续增大。
        - 固定在特定的特征维度。（按时固有跨层参数子空间的存在）固定在某些语义不重要（第一个词，最后一个词，虚词）的词上，这些词数量极少（<10），但重要。
        - 在一部分模型上，消除异常值大幅损害性能，把异常激活值换成这些巨量激活值的均值几乎不影响。（另一部分模型完全没有这种现象？）解释是异常激活值起到类似储存bias的作用（那为什么会被放这么大？干预之后这些激活值如何变化？）
    - 作者贡献
        - 对于gemma，BOS的存在与否强烈影响异常激活值，没有明显规律。gemma这个模型很独特。
        - 其他与我无关
- 结论：异常激活值并不总是有害的。
- 思考：微调关注的是参数。所以参数异常值出现在激活值激增的初始层和暴跌的末尾层，中间层模型参数是稳定的（激活值没有大的变动）。具体参数如何变化看看其他论文。

  

  

[arXiv:2402.17762](https://arxiv.org/abs/2402.17762)

---

### Massive Activations in Large Language Models

- 新知
    
    - 上一篇“前人“中的大多数
    - 比较巨量激活值（某些token的某些特征，标量）和feature outlier，发现特征维度并不重合。似乎不是直接的因果关系。
    - 比较巨量激活和top10%、median对于不同输入序列的方差，巨量激活的相对波动更小。不同token跟巨量激活的注意力分数也很相似。
    - 通过把巨量激活设置为他们的均值消除方差，不影响结果。设为0之后爆了。把其他均值附近的激活设为0之后却没有影响（对照）。结论是巨量激活对模型来说是常值，相当于bias。
    - 为什么会是这些token和位置。作者认为在开头编码自回归偏置信息最稳定，语义信息少的token编码偏置最小化对语义编码的负面影响，层间动态呈现了模型的信息流控制（没说清楚）。总体呈现最小化损失的思想。
    - 巨量激活出现之后，所有其他token之间的注意力分数都变成负的了，只有和巨量激活的logit是正的，从而在softmax之后汇聚大量注意力（点积注意力）
    
    ![[image 17.png|image 17.png]]
    
    - 从作者对LN层的图像看出，LN层的按元素仿射在**突出语义token**上有很大作用。另外因为异常值的存在，标准差很大。缩放之后值普遍变小。
    
    ![[image 1 3.png|image 1 3.png]]
    
      
    
    - 将汇聚的注意力分数与其他注意力分数剥离，跟value加权求和，观察发现汇聚注意力分数的注意力输出更稳定。
    
    ![[image 2 4.png|image 2 4.png]]
    
    - 作者尝试通过在自注意力机制中添加额外的可学习偏置项（key 和 value 向量）来显式地建模这种偏置，从而**消除对巨量激活的需求，**不影响效果而且巨量激活值消失，注意力汇聚转移到新的的偏置项。（也试过其他的显式添加偏置的方式，无效）
    
    ![[image 3 3.png|image 3 3.png]]
    
    ![[image 4 3.png|image 4 3.png]]
    
- 思考：
    
    - 我需要了解feature outlier是怎么一回事，跟activation outlier可能有什么关系。
    - 我觉得作者的偏置bias解释虽然说得通，但是不是很直接（有点隐晦）。直觉上activation outlier就像模型的注意力轴pivot，搭建起模型注意力分配的框架。不是我的研究方向，不深究。总体感觉异常值服务于稳定，正常值服务于语义。
    - LN的可学习参数（仿射变换）保留了少数异常值，增大了一般token的方差，对语义影响显著，为LN微调提供了一个解释。LN PEFT，调的就是仿射变换中的特定领域中的语义。
    
      
    

  

  

### LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale

**[arXiv:2208.07339](https://arxiv.org/abs/2208.07339)** 

- 新知：
    
    - outlier feature定义：特征值大于6, 至少影响25%的层，6%的序列。简单理解为有异常值的特征维度。
    - outlier feature只出现在注意力投射（key query）和扩张FFN（映射到高维）中（作者没有给出证明，可能是基于实验数据，但我不理解）
    - outlier features在llm参数量超过约 6B 之后普遍出现。随着模型增大，outliers增多，困惑度暴增，这个emergence现象导致量化瓶颈。outlier值和数量也随之增加。
    
    ![[image 5 3.png|image 5 3.png]]
    
    ![[image 6 3.png|image 6 3.png]]
    
    - 防止outlier影响归一化，用高精度单独量化outlier（细粒度高）。
    - 矩阵乘法可视为独立的行与列内积，因此每个向量内积使用不同的归一化参数。
    - outlier feature与outlier activation性质一致：数量少，影响大，模型固有
- 思考：本文主要讨论量化，但思想可以借鉴。不是目的导向（为了减秩设计LoRA），而是问题导向（识别限制量化的瓶颈是outlier，然后设计解决办法）。PEFT在参数量、空间占用、训练时长和下游效果的苦苦权衡是否也是被outlier限制了呢？

  

  

**[arXiv:2302.00378](https://arxiv.org/abs/2302.00378)** 

### An Empirical Study on the Transferability of Transformer Modules in Parameter-efficient Fine-tuning

- 前人：
    - Lottery Ticket Hypothesis(Prasanna et al., 2020) 存在“中奖参数/子网络”：只调参数的子集可以达到全量微调的效果，即模型的可迁移性主要取决于小部分参数。
- 新知：
    
    - 单独微调某个module都可以达到接近全量微调的效果。微调LN效果最好。解释是LN中的权重相对较大。
    - 只调整一个LN层都可以达到相当好的效果。中间层的LN可迁移性好。
    
    ![[image 7 3.png|image 7 3.png]]
    
    - LN只调整0.03%的参数，性能却挺好。单独调整attention或者ffn中的LN也不错，说明这两者中的outlier影响域有重叠。作者认为保持调整参数的consistency（在同一个module）很重要，这可不一定。
    
    ![[image 8 3.png|image 8 3.png]]
    
    - 上图为token-level-classification
    
    ![[image 9 3.png|image 9 3.png]]
    
    - 上图layer-level-LN微调。只调整一层的LN可以近似到调整所有LN的效果。
    - 分析不同module的参数分布，发现LN中呈现双峰特征，一个峰是outlier。
    
    ![[image 10 3.png|image 10 3.png]]
    
    - 作者于是只调整n个最大权重，n: 4, 16, 64, 256（算法有待改善，在定义和识别outlier和微调方面）。
    
    ![[image 11 3.png|image 11 3.png]]
    
- 思考：
    - 作者的思路让我想到了一个方向：通过研究模型的transferability分布实现PEFT。这是很自然的思考方向，但前人似乎很多都跳过了第一步：忽略能否迁移，而是工于各种高效设计。
    - 那个双峰图中说忽略了outlier？作者似乎只关注“比较大的权重”，而LN中的第二个权重峰大。这个双峰特征之前看到过相关论文[[LoRA]]，这第二个峰可否理解为LN中的outlier cluster呢？
    - 作者的忽略也意味着其他地方可能也分布着少量outlier weight。鉴于outlier如此特殊的作用，我想设计一个彻彻底底的 outlier oriented 的PEFT方法。
    - 只微调多头注意力（占25%的参数），效果比全量和FFN、LN都好。注意力头还是很重要的。依据attention sink，说不定也可以只调整attention中的部分参数。

  

### 阶段梳理：

到现在outlier activation、feature、parameter都已出现。我想整理一下这些outlier的关系。

第一篇文献研究对象是前归一化。其中GPT2使用传统LN，其他的使用RMSNorm（只除以标准差不减均值）。之后都要仿射变换，通过缩放和平移参数恢复模型表达能力。outlier activation指的是residual（$h_l = h_{l-1}+F_l(h_{l-1})$）后的输出。

outlier parameter是特别大的参数，如果在attention projection中（或者输入massivie activation）就会导致attention sink，如果在FFN中可能会导致输出massive activation，很多outlier parameter在LN中聚集，形成“双峰”。activation指的是一层的输出，如果层内的特征值出现outlier且满足一定特征，称这个特征为outlier feature。

**outlier parameter可能还蕴含着intrinsic task subspace，而第一篇论文中提到的隐式常值偏置也许正是指向这个task specific subspace的偏置向量。而这个偏置向量才是领域特定微调的关键，或者说transferability的关键。**（这可能将会是我日后提出的PEFT方法的核心假设）。

**模型不可直接学习（只能通过调整参数值大小间接学习）的相互影响：attention softmax（tokens之间作用，模型搭建注意力整体框架），layer norm（features之间作用）**。

上一篇论文中显示只微调多头注意力（占25%的参数），效果比全量和FFN、LN都好。注意力头还是很重要的。

  

### 可以给出**初步的想法**：一种彻底面向outliers的PEFT

针对每个module都有相应的方法，但不一定每一个都值得使用。比如FFN我觉得参数就太多了，LoRA最初也没有调整FFN。

1. 扫描模型每一层的每个module (batch, tokens, feature) ，**识别outliers and massive activation**。识别原则：（需要自己对着数据定量分析）
    1. massive activation: 绝对值大于100且大于1000倍的中位数
    2. outlier weight in LN
    3. outlier attention score
2. 如果在LN module有outlier，它会影响到所在**tokens dimension**中的其他特征。归一化之后，把outlier parameter(weight)所在的token（dim=2，一竖列）提出来，用**单独的仿射参数**，并只微调这对仿射参数。鉴于微调后的outlier影响域可能重叠，可以改进为**稀疏微调**：如果x是附近层的norm中异常值最大的，（x-n，x+n）区间的层内不止一层norm有异常值，只调整x层的norm仿射。n可超参数搜索。
    
    读了后面的论文后发现，模型对任务的适应很大程度山依赖outlier，因此只微调仿射效果应该不够（**可能这就是只调整LN效果比LoRA，全量略差的原因**）。更本质的是微调outlier的形成过程，要**允许模型自己调整outlier的归一前的幅值**。因此我要结合上attention 和FFN，允许模型从outlier的形成上学习适应（**这也许是LoRA很有效的原因：从形成本质上微调了outlier**）。但是或许不用低秩近似整个参数矩阵，也许也可以select。
    
3. 如果在attention module中有outlier（attention sink，这是输入了massive activation导致的），因为注意力值是经过softmax归一的，它会影响同一特征维度的其他tokens的注意力分数，所以在该特征维度的注意力分数计算时出现attention sink（模型以少数token为注意力轴）。但为了让模型更好地调整**隐式偏置**的来适应任务，把attention projection矩阵中，输出了outlier score（特大的注意力分数）的特征维度的提出来（dim=1，一横行），单独微调。微调之后把输入映射到任务适应的QKV空间，建立起任务适应的注意力轴。
    
    但**attention projection中的outlier feature不是导致massive activation现象的直接原因。**
    
4. massive activation 能够在层间保持相同的特征维度，每层的FFN模块一定起到了特殊的作用：在不同层间交互协作，建立起稳定平衡的activation space。输出了massive activation的特征维度需要微调（第二层FC），存在outlier feature的维度需要微调（第一层，如果第二层没有的话）。但是这会让可调整参数变得有点多，看微调效果权衡。

  

### BERT Busters: Outlier Dimensions that Disrupt Transformers

**[arXiv:2105.06990](https://arxiv.org/abs/2105.06990)  21年。这似乎是最早发现参数outlier的。**

- 新知：
    
    - 用3σ检验识别异常权重（RoBERTa使用2σ）。outlier的存在会导致σ变化幅度大且不稳定，而且会把没有大到可以被认为是outlier的参数识别出来（见上面论文outlier定义）。这不是一个通用的检测方法。 使用百分位数（outlier一定很少）和阈值识别应该更好。
    - 形式上，outlier 是模型的优化方向，把outrlier设为0极大的增加了交叉熵损失。
    
    ![[image 12 3.png|image 12 3.png]]
    
    - 下面两张图分别在微调之前、之后将outlier权重设为0，在下游任务上测试
        - 第一张图是微调后的，证明不同维度的feature outlier与task的性质相关，为task specific subspace假设提供支撑.
        - 第二张表中微调前消除outlier，对下游任务影响甚微，强有力的支撑了微调对outlier在任务适应上的显著影响，i.e.模型很大程度上是通过outlier之间以及outlier与non-outlier参数之间的交互来适应特定任务。
    
    ![[image 13 3.png|image 13 3.png]]
    
    ![[image 14 2.png|image 14 2.png]]
    
    - 作者的实验设计的很好（outlier+outlier，outlier+non-outlier…），充分证明了outlier的敏感性和交互特点。
    - 随机初始化的bert经过微调之后也能不错的适应特定任务 (Kovaleva et al., 2019)。作者希望在微调前消除outlier权重，模型可以通过微调完全恢复性能，但还是掉了几个点。进一步证明outlier feature的模型固有性和对任务适应的重要作用。
- 思考：
    - 作者用L1norm做的热图。但L2norm应该更能突出outlier。说到L1，也许L1正则化鼓励稀疏，突出outlier，抗噪声让模型更robust的同时，防止finetune 的时候过拟合。似乎应该是很很合适的工具，**看看有没有相关的研究。**
    - 其他想法加进了上面的“初步想法”中

  

### Attention Sinks and Outlier Features: A 'Catch, Tag, and Release' Mechanism for Embeddings

**[arXiv:2502.00919](https://arxiv.org/abs/2502.00919)**

1. **注意力汇聚点（Attention Sinks）与异常特征（Outlier Features）的协同作用**：
    - LLMs中存在特定的注意力汇聚点（如序列的首个Token），其他Token会强烈关注这些汇聚点，形成动态的注意力分配模式。
    - 异常特征（某些维度显著大于其他维度）与注意力汇聚点共同作用，形成“捕获-标记-释放”（Catch, Tag, Release）机制，用于动态组织Token序列。
2. **低秩结构的核心作用**：
    - 注意力权重矩阵的低秩结构是注意力汇聚点和异常特征产生的根本原因（A1）。
    - 通过理论分析（如平均任务），证明低秩结构是实现“捕获-标记-释放”机制的必要条件（Theorem 4.1）。
3. **剪枝方法的影响**：
    - 传统剪枝方法（如Wanda、SparseGPT）因破坏低秩结构，导致注意力汇聚点和异常特征消失，损害模型性能（图4-5）。
    - 低秩稀疏分解方法（如OATS）能保留低秩结构，维持机制有效性，在小样本学习任务中表现更优（图3）。

  

### OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for Memory-Efficient LLM Fine-tuning

**[arXiv:2405.18380](https://arxiv.org/abs/2405.18380)  没细看**

- **异常值驱动的采样策略**：
    
    通过计算每层的异常值比例（如公式2），动态分配采样概率，优先微调异常值多的层
    
    ![[image 15 2.png|image 15 2.png]]
    
    ![[image 16 2.png|image 16 2.png]]
    
- **低秩梯度投影优化内存**：
    
    对采样层的梯度进行低秩投影（基于GaLore），减少优化器状态的内存占用，同时允许增加采样层数或提升秩（rank）而不显著增加内存。
    
    ![[image 17 2.png|image 17 2.png]]
    
    ![[image 18.png]]
    
    ![[image 19.png]]
    
- 思考：
    - 提到了Lisa，一种selective PEFT方法。
    - 效果上，内存比LoRA少（不少才奇怪），平均高了1个点。
    - 作者提供的测试包含了**推理**（常识、数学）、**知识理解**（MMLU）、**生成**（对话），但不包含**代码生成**、**长文本理解**或**特定领域任务。**为什么没有用喜闻乐见的GLUE？
    - 作者的目的是实现微调效果和内存空间的最佳权衡，从outlier出发设计了倾斜采样，直接把整层采下来内存太大（主要是梯度），就低秩分解梯度。**最大的弊病是这种采样算法即无法最大限度发挥outlier的作用，可能这是该方法效果不出彩的原因；又调整了巨量non-outlier参数，浪费内存导致还要打上低秩投影的补丁。**从科研的角度上讲，感觉这种论文不纯粹，只是精心设计的方法为了在某些基准测试上做出效果，然后发出来。另外低秩投影是缝合过来的。
    - **直接层间采样细粒度不够。对outlier的理解不充分。**

  
  

### OWQ: Outlier-Aware Weight Quantization for Efficient Fine-Tuning and Inference of Large Language Models

**[arXiv:2306.02272](https://arxiv.org/abs/2306.02272)**

- **异常值驱动的量化策略**：
    
    通过Hessian矩阵和权重扰动分析，识别与激活异常值相关的敏感列（weak columns），优先保留其高精度，降低量化误差。
    
- **弱列调优（WCT）**：
    
    微调阶段仅更新敏感列，减少内存开销（如更新8列仅需6.8%参数），同时保持量化模型的性能（图4）。
    

  

  

### Lisa: Layerwise importance sampling for memory-efficient large language model fine-tuning

**[arXiv:2403.17919](https://arxiv.org/abs/2403.17919)**

![[image 20.png]]

![[image 21.png]]